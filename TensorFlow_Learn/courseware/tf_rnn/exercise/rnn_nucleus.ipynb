{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 循环核"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **什么是循环核 RNN？**\n",
    "\n",
    "循环核 RNN（Recurrent Neural Network）是一种特殊的神经网络结构，用于处理序列数据。它与普通神经网络不同，它具有循环连接，允许网络在处理每个输入时，根据之前输入和输出的状态来更新状态。循环核 RNN在处理序列数据时，可以记住之前的输入和输出状态，从而实现对序列数据的处理。\n",
    "在 RNN 中，循环核（Recurrent Kernel）通常指的是网络内部负责处理时间序列依赖关系的 权重矩阵 或 非线性变换，它是网络的核心计算单元，负责将当前的输入和先前的隐藏状态结合起来，生成当前的隐藏状态。\n",
    "\n",
    "具体来说，RNN 的核心循环计算如下：\n",
    "$$\n",
    "h_t = f(W_{xh} \\cdot x_t + W_{hh} \\cdot h_{t-1} + b_h)\n",
    "$$\n",
    "- h_t ：当前时间步的隐藏状态。\n",
    "- x_t ：当前时间步的输入。\n",
    "- W_{xh} ：输入到隐藏状态的权重矩阵。\n",
    "- W_{hh} ：隐藏状态到隐藏状态的循环核（recurrent kernel）。\n",
    "- b_h ：偏置项。\n",
    "- f ：非线性激活函数（如 tanh 或 ReLU）。\n",
    "\n",
    "其中， $W_{hh}$  就是循环核的权重矩阵，它负责捕获序列中的时间依赖性。\n",
    "\n",
    "<img src=\"spread.png\" width=\"500\" height=\"300\" />\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **RNN 按时间步展开**\n",
    "```text\n",
    "\n",
    "在循环神经网络（Recurrent Neural Network, RNN）中，按时间步展开是将递归计算的结构表示为一个 时间序列上的链式结构，以便直观地理解时间步之间的信息流动和依赖关系。这一展开过程称为 时间展开（Unrolling or Time Unfolding）。\n",
    "\n",
    "\n",
    "展开后的时间序列结构如下：\n",
    "\n",
    "时间步 1:       时间步 2:       时间步 3:\n",
    "x_1 --->[RNN]--->x_2 --->[RNN]--->x_3 --->[RNN]--->...\n",
    "         |              |              |\n",
    "         h_1            h_2            h_3\n",
    "         |              |              |\n",
    "         y_1            y_2            y_3\n",
    "\n",
    "时间展开的特性\n",
    "\t1.\t共享参数：所有时间步上的权重矩阵（如 ￼、￼、￼）是共享的，这使得 RNN 能够处理任意长度的序列。\n",
    "\t2.\t时间依赖：当前时间步的隐藏状态 ￼ 依赖于所有之前时间步的状态 ￼，从而捕获序列中的时间依赖性。\n",
    "\t3.\t反向传播（BPTT）：通过时间展开，反向传播可以计算所有时间步上的梯度，从而优化共享参数。这种优化方法称为 时间上的反向传播算法（Backpropagation Through Time, BPTT）。\n",
    "\n",
    "优势和用途\n",
    "\t•\t直观性：时间展开清晰地显示了序列中各时间步之间的依赖关系。\n",
    "\t•\t适用性：支持变长输入序列，适用于时间序列预测、自然语言处理、语音识别等任务。\n",
    "\n",
    "展开后的 RNN 提供了一种处理序列数据的有效方法，但在长序列中可能会遇到梯度消失和爆炸问题，这需要通过改进（如 LSTM 或 GRU）来解决。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **循环计算层**\n",
    "\n",
    "向输出方向生长\n",
    "\n",
    "<img src=\"rnn_cal.png\" width=\"500\" height=\"300\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **TensorFlow描述循环计算层**\n",
    "\n",
    "tf.keras.layers.SimpleRNN(记忆体个数，activation='激活函数',return_sequences=是否每个时刻输出ht到下一层)\n",
    "\n",
    "- activation：激活函数 不写默认为tanh\n",
    "- return_sequences：是否每个时刻输出ht到下一层，默认为False，只输出最后一个时刻的ht到下一层。\n",
    "\n",
    "\n",
    "<img src=\"rnn_return_seq_true.png\" width=\"500\" height=\"300\" />\n",
    "\n",
    "\n",
    "<img src=\"rnn_return_seq_false.png\" width=\"500\" height=\"300\" />\n",
    "\n",
    "\n",
    "<img src=\"rnn_train_level.png\" width=\"500\" height=\"300\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 字母预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  **字母预测**，用RNN实现输入一个字母，预测下一个字母（OneHot编码）\n",
    "\n",
    "输入a预测b，输入b预测c，输入c预测d，输入d预测e，输入e预测a。\n",
    "\n",
    "**循环计算过程** ：\n",
    "\n",
    "<img src=\"cnn_onehot_1pre1_01.png\" width=\"500\" height=\"300\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导包\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "input_word = \"abcde\"\n",
    "\n",
    "# 创建一个映射表\n",
    "w_to_id = {'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4}  # 单词映射到数值id的词典\n",
    "id_to_onehot = {0: [1., 0., 0., 0., 0.], 1: [0., 1., 0., 0., 0.], 2: [0., 0., 1., 0., 0.], 3: [0., 0., 0., 1., 0.],\n",
    "                4: [0., 0., 0., 0., 1.]}  # id编码为one-hot\n",
    "\n",
    "x_train = [id_to_onehot[w_to_id['a']], id_to_onehot[w_to_id['b']], id_to_onehot[w_to_id['c']],\n",
    "           id_to_onehot[w_to_id['d']], id_to_onehot[w_to_id['e']]]\n",
    "y_train = [w_to_id['b'], w_to_id['c'], w_to_id['d'], w_to_id['e'], w_to_id['a']]\n",
    "\n",
    "np.random.seed(7)\n",
    "np.random.shuffle(x_train)\n",
    "np.random.seed(7)\n",
    "np.random.shuffle(y_train)\n",
    "tf.random.set_seed(7)\n",
    "\n",
    "# 使x_train符合SimpleRNN输入要求：[送入样本数， 循环核时间展开步数， 每个时间步输入特征个数]。\n",
    "x_train = np.reshape(x_train, (len(x_train), 1, 5))\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    SimpleRNN(3),\n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.legacy.Adam(0.01),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "# 断点续训\n",
    "checkpoint_save_path = \"./checkpoint/rnn_onehot_1pre1.ckpt\"\n",
    "if os.path.exists(checkpoint_save_path + '.index'):\n",
    "    print('-------------load the model-----------------')\n",
    "    model.load_weights(checkpoint_save_path)\n",
    "    \n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_save_path,\n",
    "                                                    save_weights_only=True,\n",
    "                                                    save_best_only=True,\n",
    "                                                    monitor='loss')\n",
    "history = model.fit(x_train, y_train, batch_size=32, epochs=100, callbacks=[cp_callback])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 参数提取\n",
    "# print(model.trainable_variables)\n",
    "file = open('./weights.txt', 'w')  # 参数提取\n",
    "for v in model.trainable_variables:\n",
    "    file.write(str(v.name) + '\\n')\n",
    "    file.write(str(v.shape) + '\\n')\n",
    "    file.write(str(v.numpy()) + '\\n')\n",
    "file.close()\n",
    "\n",
    "###############################################    show   ###############################################\n",
    "\n",
    "# 显示训练集和验证集的acc和loss曲线\n",
    "acc = history.history['sparse_categorical_accuracy']\n",
    "loss = history.history['loss']\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### predict #############\n",
    "\n",
    "preNum = int(input(\"input the number of test alphabet:\"))\n",
    "for i in range(preNum):\n",
    "    alphabet1 = input(\"input test alphabet:\")\n",
    "    alphabet = [id_to_onehot[w_to_id[alphabet1]]]\n",
    "    # 使alphabet符合SimpleRNN输入要求：[送入样本数， 循环核时间展开步数， 每个时间步输入特征个数]。此处验证效果送入了1个样本，送入样本数为1；输入1个字母出结果，所以循环核时间展开步数为1; 表示为独热码有5个输入特征，每个时间步输入特征个数为5\n",
    "    alphabet = np.reshape(alphabet, (1, 1, 5))\n",
    "    result = model.predict([alphabet])\n",
    "    pred = tf.argmax(result, axis=1)\n",
    "    pred = int(pred)\n",
    "    tf.print(alphabet1 + '->' + input_word[pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 字母预测，用RNN实现输入连续的4个字母，预测下一个字母\n",
    "\n",
    "输入a b c d，输出e, 输入b c d e，输出a ...\n",
    "\n",
    "\n",
    "<img src=\"cnn_onehot_4pre1_02.png\" width=\"500\" height=\"300\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "input_word = \"abcde\"\n",
    "w_to_id = {'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4}  # 单词映射到数值id的词典\n",
    "id_to_onehot = {0: [1., 0., 0., 0., 0.], 1: [0., 1., 0., 0., 0.], 2: [0., 0., 1., 0., 0.], 3: [0., 0., 0., 1., 0.],\n",
    "                4: [0., 0., 0., 0., 1.]}  # id编码为one-hot\n",
    "\n",
    "x_train = [\n",
    "    [id_to_onehot[w_to_id['a']], id_to_onehot[w_to_id['b']], id_to_onehot[w_to_id['c']], id_to_onehot[w_to_id['d']]],\n",
    "    [id_to_onehot[w_to_id['b']], id_to_onehot[w_to_id['c']], id_to_onehot[w_to_id['d']], id_to_onehot[w_to_id['e']]],\n",
    "    [id_to_onehot[w_to_id['c']], id_to_onehot[w_to_id['d']], id_to_onehot[w_to_id['e']], id_to_onehot[w_to_id['a']]],\n",
    "    [id_to_onehot[w_to_id['d']], id_to_onehot[w_to_id['e']], id_to_onehot[w_to_id['a']], id_to_onehot[w_to_id['b']]],\n",
    "    [id_to_onehot[w_to_id['e']], id_to_onehot[w_to_id['a']], id_to_onehot[w_to_id['b']], id_to_onehot[w_to_id['c']]],\n",
    "]\n",
    "y_train = [w_to_id['e'], w_to_id['a'], w_to_id['b'], w_to_id['c'], w_to_id['d']]\n",
    "\n",
    "np.random.seed(7)\n",
    "np.random.shuffle(x_train)\n",
    "np.random.seed(7)\n",
    "np.random.shuffle(y_train)\n",
    "tf.random.set_seed(7)\n",
    "\n",
    "# 使x_train符合SimpleRNN输入要求：[送入样本数， 循环核时间展开步数， 每个时间步输入特征个数]。\n",
    "# 此处整个数据集送入，送入样本数为len(x_train)；输入4个字母出结果，循环核时间展开步数为4; 表示为独热码有5个输入特征，每个时间步输入特征个数为5\n",
    "x_train = np.reshape(x_train, (len(x_train), 4, 5))\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    SimpleRNN(3),\n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "checkpoint_save_path = \"./checkpoint/rnn_onehot_4pre1.ckpt\"\n",
    "\n",
    "if os.path.exists(checkpoint_save_path + '.index'):\n",
    "    print('-------------load the model-----------------')\n",
    "    model.load_weights(checkpoint_save_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_save_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 save_best_only=True,\n",
    "                                                 monitor='loss')  # 由于fit没有给出测试集，不计算测试集准确率，根据loss，保存最优模型\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=32, epochs=100, callbacks=[cp_callback])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# print(model.trainable_variables)\n",
    "file = open('./weights.txt', 'w')  # 参数提取\n",
    "for v in model.trainable_variables:\n",
    "    file.write(str(v.name) + '\\n')\n",
    "    file.write(str(v.shape) + '\\n')\n",
    "    file.write(str(v.numpy()) + '\\n')\n",
    "file.close()\n",
    "\n",
    "###############################################    show   ###############################################\n",
    "\n",
    "# 显示训练集和验证集的acc和loss曲线\n",
    "acc = history.history['sparse_categorical_accuracy']\n",
    "loss = history.history['loss']\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "############### predict #############\n",
    "\n",
    "preNum = int(input(\"input the number of test alphabet:\"))\n",
    "for i in range(preNum):\n",
    "    alphabet1 = input(\"input test alphabet:\")\n",
    "    alphabet = [id_to_onehot[w_to_id[a]] for a in alphabet1]\n",
    "    # 使alphabet符合SimpleRNN输入要求：[送入样本数， 循环核时间展开步数， 每个时间步输入特征个数]。此处验证效果送入了1个样本，送入样本数为1；输入4个字母出结果，所以循环核时间展开步数为4; 表示为独热码有5个输入特征，每个时间步输入特征个数为5\n",
    "    alphabet = np.reshape(alphabet, (1, 4, 5))\n",
    "    result = model.predict([alphabet])\n",
    "    pred = tf.argmax(result, axis=1)\n",
    "    pred = int(pred)\n",
    "    tf.print(alphabet1 + '->' + input_word[pred])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 字母预测，使用Embedding层和RNN层\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, Embedding\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "input_word = \"abcde\"\n",
    "w_to_id = {'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4}  # 单词映射到数值id的词典\n",
    "\n",
    "x_train = [w_to_id['a'], w_to_id['b'], w_to_id['c'], w_to_id['d'], w_to_id['e']]\n",
    "y_train = [w_to_id['b'], w_to_id['c'], w_to_id['d'], w_to_id['e'], w_to_id['a']]\n",
    "\n",
    "np.random.seed(7)\n",
    "np.random.shuffle(x_train)\n",
    "np.random.seed(7)\n",
    "np.random.shuffle(y_train)\n",
    "tf.random.set_seed(7)\n",
    "\n",
    "# 使x_train符合Embedding输入要求：[送入样本数， 循环核时间展开步数] ，\n",
    "# 此处整个数据集送入所以送入，送入样本数为len(x_train)；输入1个字母出结果，循环核时间展开步数为1。\n",
    "x_train = np.reshape(x_train, (len(x_train), 1))\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    Embedding(5, 2),\n",
    "    SimpleRNN(3),\n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "checkpoint_save_path = \"./checkpoint/run_embedding_1pre1.ckpt\"\n",
    "\n",
    "if os.path.exists(checkpoint_save_path + '.index'):\n",
    "    print('-------------load the model-----------------')\n",
    "    model.load_weights(checkpoint_save_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_save_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 save_best_only=True,\n",
    "                                                 monitor='loss')  # 由于fit没有给出测试集，不计算测试集准确率，根据loss，保存最优模型\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=32, epochs=100, callbacks=[cp_callback])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# print(model.trainable_variables)\n",
    "file = open('./weights.txt', 'w')  # 参数提取\n",
    "for v in model.trainable_variables:\n",
    "    file.write(str(v.name) + '\\n')\n",
    "    file.write(str(v.shape) + '\\n')\n",
    "    file.write(str(v.numpy()) + '\\n')\n",
    "file.close()\n",
    "\n",
    "###############################################    show   ###############################################\n",
    "\n",
    "# 显示训练集和验证集的acc和loss曲线\n",
    "acc = history.history['sparse_categorical_accuracy']\n",
    "loss = history.history['loss']\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "############### predict #############\n",
    "\n",
    "preNum = int(input(\"input the number of test alphabet:\"))\n",
    "for i in range(preNum):\n",
    "    alphabet1 = input(\"input test alphabet:\")\n",
    "    alphabet = [w_to_id[alphabet1]]\n",
    "    # 使alphabet符合Embedding输入要求：[送入样本数， 循环核时间展开步数]。\n",
    "    # 此处验证效果送入了1个样本，送入样本数为1；输入1个字母出结果，循环核时间展开步数为1。\n",
    "    alphabet = np.reshape(alphabet, (1, 1))\n",
    "    result = model.predict(alphabet)\n",
    "    pred = tf.argmax(result, axis=1)\n",
    "    pred = int(pred)\n",
    "    tf.print(alphabet1 + '->' + input_word[pred])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 字母预测，使用Embedding层和RNN层,输入4个字，预测下一个字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, Embedding\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "input_word = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "w_to_id = {'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4,\n",
    "           'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9,\n",
    "           'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14,\n",
    "           'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19,\n",
    "           'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25}  # 单词映射到数值id的词典\n",
    "\n",
    "training_set_scaled = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
    "                       11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n",
    "                       21, 22, 23, 24, 25]\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(4, 26):\n",
    "    x_train.append(training_set_scaled[i - 4:i])\n",
    "    y_train.append(training_set_scaled[i])\n",
    "\n",
    "np.random.seed(7)\n",
    "np.random.shuffle(x_train)\n",
    "np.random.seed(7)\n",
    "np.random.shuffle(y_train)\n",
    "tf.random.set_seed(7)\n",
    "\n",
    "# 使x_train符合Embedding输入要求：[送入样本数， 循环核时间展开步数] ，\n",
    "# 此处整个数据集送入所以送入，送入样本数为len(x_train)；输入4个字母出结果，循环核时间展开步数为4。\n",
    "x_train = np.reshape(x_train, (len(x_train), 4))\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    Embedding(26, 2),\n",
    "    SimpleRNN(10),\n",
    "    Dense(26, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "checkpoint_save_path = \"./checkpoint/rnn_embedding_4pre1.ckpt\"\n",
    "\n",
    "if os.path.exists(checkpoint_save_path + '.index'):\n",
    "    print('-------------load the model-----------------')\n",
    "    model.load_weights(checkpoint_save_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_save_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 save_best_only=True,\n",
    "                                                 monitor='loss')  # 由于fit没有给出测试集，不计算测试集准确率，根据loss，保存最优模型\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=32, epochs=100, callbacks=[cp_callback])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "file = open('./weights.txt', 'w')  # 参数提取\n",
    "for v in model.trainable_variables:\n",
    "    file.write(str(v.name) + '\\n')\n",
    "    file.write(str(v.shape) + '\\n')\n",
    "    file.write(str(v.numpy()) + '\\n')\n",
    "file.close()\n",
    "\n",
    "###############################################    show   ###############################################\n",
    "\n",
    "# 显示训练集和验证集的acc和loss曲线\n",
    "acc = history.history['sparse_categorical_accuracy']\n",
    "loss = history.history['loss']\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "################# predict ##################\n",
    "\n",
    "preNum = int(input(\"input the number of test alphabet:\"))\n",
    "for i in range(preNum):\n",
    "    alphabet1 = input(\"input test alphabet:\")\n",
    "    alphabet = [w_to_id[a] for a in alphabet1]\n",
    "    # 使alphabet符合Embedding输入要求：[送入样本数， 时间展开步数]。\n",
    "    # 此处验证效果送入了1个样本，送入样本数为1；输入4个字母出结果，循环核时间展开步数为4。\n",
    "    alphabet = np.reshape(alphabet, (1, 4))\n",
    "    result = model.predict([alphabet])\n",
    "    pred = tf.argmax(result, axis=1)\n",
    "    pred = int(pred)\n",
    "    tf.print(alphabet1 + '->' + input_word[pred])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 股票预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tushare as ts\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 设置 tushare 的 token\n",
    "# 请替换 'your_token_here' 为你的实际 token\n",
    "ts.set_token('4c914f42efa0f9ddec5978afbbc1681a21205c84ec60ab99aa8cd75e')\n",
    "pro = ts.pro_api()\n",
    "\n",
    "# 获取贵州茅台（600519）股票日线数据\n",
    "df1 = pro.daily(ts_code='600519.SH', start_date='20200101', end_date='20250101')\n",
    "\n",
    "# 保存数据到 CSV 文件\n",
    "datapath1 = \"./SH600519.csv\"\n",
    "df1.to_csv(datapath1, index=False)\n",
    "\n",
    "# 打印数据预览\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dropout, Dense, SimpleRNN\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import math\n",
    "\n",
    "maotai = pd.read_csv('./SH600519.csv')  # 读取股票文件\n",
    "\n",
    "training_set = maotai.iloc[0:1200 - 100, 2:3].values  # 前(2426-300=2126)天的开盘价作为训练集,表格从0开始计数，2:3 是提取[2:3)列，前闭后开,故提取出C列开盘价\n",
    "test_set = maotai.iloc[1200 - 1200:, 2:3].values  # 后300天的开盘价作为测试集\n",
    "\n",
    "# 归一化\n",
    "sc = MinMaxScaler(feature_range=(0, 1))  # 定义归一化：归一化到(0，1)之间\n",
    "training_set_scaled = sc.fit_transform(training_set)  # 求得训练集的最大值，最小值这些训练集固有的属性，并在训练集上进行归一化\n",
    "test_set = sc.transform(test_set)  # 利用训练集的属性对测试集进行归一化\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "# 测试集：csv表格中前2426-300=2126天数据\n",
    "# 利用for循环，遍历整个训练集，提取训练集中连续60天的开盘价作为输入特征x_train，第61天的数据作为标签，for循环共构建2426-300-60=2066组数据。\n",
    "for i in range(60, len(training_set_scaled)):\n",
    "    x_train.append(training_set_scaled[i - 60:i, 0])\n",
    "    y_train.append(training_set_scaled[i, 0])\n",
    "# 对训练集进行打乱\n",
    "np.random.seed(7)\n",
    "np.random.shuffle(x_train)\n",
    "np.random.seed(7)\n",
    "np.random.shuffle(y_train)\n",
    "tf.random.set_seed(7)\n",
    "# 将训练集由list格式变为array格式\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "# 使x_train符合RNN输入要求：[送入样本数， 循环核时间展开步数， 每个时间步输入特征个数]。\n",
    "# 此处整个数据集送入，送入样本数为x_train.shape[0]即2066组数据；输入60个开盘价，预测出第61天的开盘价，循环核时间展开步数为60; 每个时间步送入的特征是某一天的开盘价，只有1个数据，故每个时间步输入特征个数为1\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], 60, 1))\n",
    "# 测试集：csv表格中后300天数据\n",
    "# 利用for循环，遍历整个测试集，提取测试集中连续60天的开盘价作为输入特征x_train，第61天的数据作为标签，for循环共构建300-60=240组数据。\n",
    "for i in range(60, len(test_set)):\n",
    "    x_test.append(test_set[i - 60:i, 0])\n",
    "    y_test.append(test_set[i, 0])\n",
    "# 测试集变array并reshape为符合RNN输入要求：[送入样本数， 循环核时间展开步数， 每个时间步输入特征个数]\n",
    "x_test, y_test = np.array(x_test), np.array(y_test)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], 60, 1))\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    SimpleRNN(80, return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    SimpleRNN(100),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss='mean_squared_error')  # 损失函数用均方误差\n",
    "# 该应用只观测loss数值，不观测准确率，所以删去metrics选项，一会在每个epoch迭代显示时只显示loss值\n",
    "\n",
    "checkpoint_save_path = \"./checkpoint/rnn_stock.ckpt\"\n",
    "\n",
    "if os.path.exists(checkpoint_save_path + '.index'):\n",
    "    print('-------------load the model-----------------')\n",
    "    model.load_weights(checkpoint_save_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_save_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 save_best_only=True,\n",
    "                                                 monitor='val_loss')\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=64, epochs=50, validation_data=(x_test, y_test), validation_freq=1,\n",
    "                    callbacks=[cp_callback])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "file = open('./weights.txt', 'w')  # 参数提取\n",
    "for v in model.trainable_variables:\n",
    "    file.write(str(v.name) + '\\n')\n",
    "    file.write(str(v.shape) + '\\n')\n",
    "    file.write(str(v.numpy()) + '\\n')\n",
    "file.close()\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## predict ######################\n",
    "# 测试集输入模型进行预测\n",
    "predicted_stock_price = model.predict(x_test)\n",
    "# 对预测数据还原---从（0，1）反归一化到原始范围\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)\n",
    "# 对真实数据还原---从（0，1）反归一化到原始范围\n",
    "real_stock_price = sc.inverse_transform(test_set[60:])\n",
    "# 画出真实数据和预测数据的对比曲线\n",
    "plt.plot(real_stock_price, color='red', label='MaoTai Stock Price')\n",
    "plt.plot(predicted_stock_price, color='blue', label='Predicted MaoTai Stock Price')\n",
    "plt.title('MaoTai Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('MaoTai Stock Price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "##########evaluate##############\n",
    "# calculate MSE 均方误差 ---> E[(预测值-真实值)^2] (预测值减真实值求平方后求均值)\n",
    "mse = mean_squared_error(predicted_stock_price, real_stock_price)\n",
    "# calculate RMSE 均方根误差--->sqrt[MSE]    (对均方误差开方)\n",
    "rmse = math.sqrt(mean_squared_error(predicted_stock_price, real_stock_price))\n",
    "# calculate MAE 平均绝对误差----->E[|预测值-真实值|](预测值减真实值求绝对值后求均值）\n",
    "mae = mean_absolute_error(predicted_stock_price, real_stock_price)\n",
    "print('均方误差: %.6f' % mse)\n",
    "print('均方根误差: %.6f' % rmse)\n",
    "print('平均绝对误差: %.6f' % mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dropout, Dense, LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import math\n",
    "\n",
    "maotai = pd.read_csv('./SH600519.csv')  # 读取股票文件\n",
    "\n",
    "training_set = maotai.iloc[0:1200 - 300, 2:3].values  # 前(2426-300=2126)天的开盘价作为训练集,表格从0开始计数，2:3 是提取[2:3)列，前闭后开,故提取出C列开盘价\n",
    "test_set = maotai.iloc[1200 - 300:, 2:3].values  # 后300天的开盘价作为测试集\n",
    "\n",
    "# 归一化\n",
    "sc = MinMaxScaler(feature_range=(0, 1))  # 定义归一化：归一化到(0，1)之间\n",
    "training_set_scaled = sc.fit_transform(training_set)  # 求得训练集的最大值，最小值这些训练集固有的属性，并在训练集上进行归一化\n",
    "test_set = sc.transform(test_set)  # 利用训练集的属性对测试集进行归一化\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "# 测试集：csv表格中前2426-300=2126天数据\n",
    "# 利用for循环，遍历整个训练集，提取训练集中连续60天的开盘价作为输入特征x_train，第61天的数据作为标签，for循环共构建2426-300-60=2066组数据。\n",
    "for i in range(60, len(training_set_scaled)):\n",
    "    x_train.append(training_set_scaled[i - 60:i, 0])\n",
    "    y_train.append(training_set_scaled[i, 0])\n",
    "# 对训练集进行打乱\n",
    "np.random.seed(7)\n",
    "np.random.shuffle(x_train)\n",
    "np.random.seed(7)\n",
    "np.random.shuffle(y_train)\n",
    "tf.random.set_seed(7)\n",
    "# 将训练集由list格式变为array格式\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "# 使x_train符合RNN输入要求：[送入样本数， 循环核时间展开步数， 每个时间步输入特征个数]。\n",
    "# 此处整个数据集送入，送入样本数为x_train.shape[0]即2066组数据；输入60个开盘价，预测出第61天的开盘价，循环核时间展开步数为60; 每个时间步送入的特征是某一天的开盘价，只有1个数据，故每个时间步输入特征个数为1\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], 60, 1))\n",
    "# 测试集：csv表格中后300天数据\n",
    "# 利用for循环，遍历整个测试集，提取测试集中连续60天的开盘价作为输入特征x_train，第61天的数据作为标签，for循环共构建300-60=240组数据。\n",
    "for i in range(60, len(test_set)):\n",
    "    x_test.append(test_set[i - 60:i, 0])\n",
    "    y_test.append(test_set[i, 0])\n",
    "# 测试集变array并reshape为符合RNN输入要求：[送入样本数， 循环核时间展开步数， 每个时间步输入特征个数]\n",
    "x_test, y_test = np.array(x_test), np.array(y_test)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], 60, 1))\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    LSTM(80, return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(100),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss='mean_squared_error')  # 损失函数用均方误差\n",
    "# 该应用只观测loss数值，不观测准确率，所以删去metrics选项，一会在每个epoch迭代显示时只显示loss值\n",
    "\n",
    "checkpoint_save_path = \"./checkpoint/LSTM_stock.ckpt\"\n",
    "\n",
    "if os.path.exists(checkpoint_save_path + '.index'):\n",
    "    print('-------------load the model-----------------')\n",
    "    model.load_weights(checkpoint_save_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_save_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 save_best_only=True,\n",
    "                                                 monitor='val_loss')\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=64, epochs=50, validation_data=(x_test, y_test), validation_freq=1,\n",
    "                    callbacks=[cp_callback])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "file = open('./weights.txt', 'w')  # 参数提取\n",
    "for v in model.trainable_variables:\n",
    "    file.write(str(v.name) + '\\n')\n",
    "    file.write(str(v.shape) + '\\n')\n",
    "    file.write(str(v.numpy()) + '\\n')\n",
    "file.close()\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "################## predict ######################\n",
    "# 测试集输入模型进行预测\n",
    "predicted_stock_price = model.predict(x_test)\n",
    "# 对预测数据还原---从（0，1）反归一化到原始范围\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)\n",
    "# 对真实数据还原---从（0，1）反归一化到原始范围\n",
    "real_stock_price = sc.inverse_transform(test_set[60:])\n",
    "# 画出真实数据和预测数据的对比曲线\n",
    "plt.plot(real_stock_price, color='red', label='MaoTai Stock Price')\n",
    "plt.plot(predicted_stock_price, color='blue', label='Predicted MaoTai Stock Price')\n",
    "plt.title('MaoTai Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('MaoTai Stock Price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "##########evaluate##############\n",
    "# calculate MSE 均方误差 ---> E[(预测值-真实值)^2] (预测值减真实值求平方后求均值)\n",
    "mse = mean_squared_error(predicted_stock_price, real_stock_price)\n",
    "# calculate RMSE 均方根误差--->sqrt[MSE]    (对均方误差开方)\n",
    "rmse = math.sqrt(mean_squared_error(predicted_stock_price, real_stock_price))\n",
    "# calculate MAE 平均绝对误差----->E[|预测值-真实值|](预测值减真实值求绝对值后求均值）\n",
    "mae = mean_absolute_error(predicted_stock_price, real_stock_price)\n",
    "print('均方误差: %.6f' % mse)\n",
    "print('均方根误差: %.6f' % rmse)\n",
    "print('平均绝对误差: %.6f' % mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dropout, Dense, GRU\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import math\n",
    "\n",
    "maotai = pd.read_csv('./SH600519.csv')  # 读取股票文件\n",
    "\n",
    "training_set = maotai.iloc[0:1200 - 300, 2:3].values  # 前(2426-300=2126)天的开盘价作为训练集,表格从0开始计数，2:3 是提取[2:3)列，前闭后开,故提取出C列开盘价\n",
    "test_set = maotai.iloc[1200 - 300:, 2:3].values  # 后300天的开盘价作为测试集\n",
    "\n",
    "# 归一化\n",
    "sc = MinMaxScaler(feature_range=(0, 1))  # 定义归一化：归一化到(0，1)之间\n",
    "training_set_scaled = sc.fit_transform(training_set)  # 求得训练集的最大值，最小值这些训练集固有的属性，并在训练集上进行归一化\n",
    "test_set = sc.transform(test_set)  # 利用训练集的属性对测试集进行归一化\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "# 测试集：csv表格中前2426-300=2126天数据\n",
    "# 利用for循环，遍历整个训练集，提取训练集中连续60天的开盘价作为输入特征x_train，第61天的数据作为标签，for循环共构建2426-300-60=2066组数据。\n",
    "for i in range(60, len(training_set_scaled)):\n",
    "    x_train.append(training_set_scaled[i - 60:i, 0])\n",
    "    y_train.append(training_set_scaled[i, 0])\n",
    "# 对训练集进行打乱\n",
    "np.random.seed(7)\n",
    "np.random.shuffle(x_train)\n",
    "np.random.seed(7)\n",
    "np.random.shuffle(y_train)\n",
    "tf.random.set_seed(7)\n",
    "# 将训练集由list格式变为array格式\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "# 使x_train符合RNN输入要求：[送入样本数， 循环核时间展开步数， 每个时间步输入特征个数]。\n",
    "# 此处整个数据集送入，送入样本数为x_train.shape[0]即2066组数据；输入60个开盘价，预测出第61天的开盘价，循环核时间展开步数为60; 每个时间步送入的特征是某一天的开盘价，只有1个数据，故每个时间步输入特征个数为1\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], 60, 1))\n",
    "# 测试集：csv表格中后300天数据\n",
    "# 利用for循环，遍历整个测试集，提取测试集中连续60天的开盘价作为输入特征x_train，第61天的数据作为标签，for循环共构建300-60=240组数据。\n",
    "for i in range(60, len(test_set)):\n",
    "    x_test.append(test_set[i - 60:i, 0])\n",
    "    y_test.append(test_set[i, 0])\n",
    "# 测试集变array并reshape为符合RNN输入要求：[送入样本数， 循环核时间展开步数， 每个时间步输入特征个数]\n",
    "x_test, y_test = np.array(x_test), np.array(y_test)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], 60, 1))\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    GRU(80, return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    GRU(100),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss='mean_squared_error')  # 损失函数用均方误差\n",
    "# 该应用只观测loss数值，不观测准确率，所以删去metrics选项，一会在每个epoch迭代显示时只显示loss值\n",
    "\n",
    "checkpoint_save_path = \"./checkpoint/stock.ckpt\"\n",
    "\n",
    "if os.path.exists(checkpoint_save_path + '.index'):\n",
    "    print('-------------load the model-----------------')\n",
    "    model.load_weights(checkpoint_save_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_save_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 save_best_only=True,\n",
    "                                                 monitor='val_loss')\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=64, epochs=50, validation_data=(x_test, y_test), validation_freq=1,\n",
    "                    callbacks=[cp_callback])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "file = open('./weights.txt', 'w')  # 参数提取\n",
    "for v in model.trainable_variables:\n",
    "    file.write(str(v.name) + '\\n')\n",
    "    file.write(str(v.shape) + '\\n')\n",
    "    file.write(str(v.numpy()) + '\\n')\n",
    "file.close()\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "################## predict ######################\n",
    "# 测试集输入模型进行预测\n",
    "predicted_stock_price = model.predict(x_test)\n",
    "# 对预测数据还原---从（0，1）反归一化到原始范围\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)\n",
    "# 对真实数据还原---从（0，1）反归一化到原始范围\n",
    "real_stock_price = sc.inverse_transform(test_set[60:])\n",
    "# 画出真实数据和预测数据的对比曲线\n",
    "plt.plot(real_stock_price, color='red', label='MaoTai Stock Price')\n",
    "plt.plot(predicted_stock_price, color='blue', label='Predicted MaoTai Stock Price')\n",
    "plt.title('MaoTai Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('MaoTai Stock Price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "##########evaluate##############\n",
    "# calculate MSE 均方误差 ---> E[(预测值-真实值)^2] (预测值减真实值求平方后求均值)\n",
    "mse = mean_squared_error(predicted_stock_price, real_stock_price)\n",
    "# calculate RMSE 均方根误差--->sqrt[MSE]    (对均方误差开方)\n",
    "rmse = math.sqrt(mean_squared_error(predicted_stock_price, real_stock_price))\n",
    "# calculate MAE 平均绝对误差----->E[|预测值-真实值|](预测值减真实值求绝对值后求均值）\n",
    "mae = mean_absolute_error(predicted_stock_price, real_stock_price)\n",
    "print('均方误差: %.6f' % mse)\n",
    "print('均方根误差: %.6f' % rmse)\n",
    "print('平均绝对误差: %.6f' % mae)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
